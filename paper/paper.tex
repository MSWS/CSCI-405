\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{setspace}

\doublespacing                    

\begin{document}

\title{Filter Bubbles}
\author{Isaac Boaz}
\maketitle

\begin{abstract}
    The term `filter bubble' was coined by Eli Pariser. This paper will explore
    the implications of filter bubbles on society, and how they have changed the
    internet. This paper will describe how filter bubbles have affected society,
    and argue why they \emph{are an important factor for society}.
\end{abstract}


\section{Introduction}
The idea of filter bubbles was created by Eli Pariser \cite{elifilter}. The idea
relates to how the public disseminates content, and how the internet has
changed the way we consume information. In short, the internet has allowed (if
not required) websites to develop automated algorithms for prioritizing and
delivering content to users. One of the key points Pariser makes is that
the change in how we filter information has led to people being `lazier' in
their consumption of information.

Pariser describes how although people may have skipped over the front page of a
newspaper, they would still be exposed to the headlines. Quoting Clary Shark,
Pariser writes `But to do so, they had to at least glance at the front page -- and
so, if there was a huge political scandal, enough people would know about it to
make an impact at the polls' \cite{elifilter}.

In contrast, Pariser goes on, the internet allows for filtering out content
before it even reaches the user. The modern internet now hinges on having some
form of filtering in place, and many services (such as Google, YouTube, and
other social media) extend this filter into the bubble that Pariser describes.

This brings up the question of how filter bubbles are affecting society.
Pariser argues that filter bubbles are a `threat to democracy', and take power
away from the people. Websites are now the deciders of what content you do (or
don't) see.

\section{Analysis}
\subsection{Historic Prevalence in News}
The internet has enabled any person to generate content and share it with the
world. This has led to an explosion of information, and the need to filter out
the noise. The goal of the internet ultimately is to spread information. News
sites and social media platforms at the end of the day need to stay profitable.
Filter bubbles aren't only pertinent to these types of sites, but any with a
large amount of content is reliant on filtering.

Filter bubbles are absolutely an important factor for society. Whether a website
wants to find the next article that you are most likely going to click on, or
Amazon trying to suggest to you new products in their story, filter bubbles
dictate the content that people see.

A similar idea to filter bubbles is the idea of echo chambers. Dr. Richard
Fletcher points out an important distinction between filter bubbles and echo
chambers:

\begin{quote}
    `An echo chamber is what might happen when we are overexposed to news that
    we like or agree with, potentially distorting our perception of reality
    because we see too much of one side, not enough of the other, and we start
    to think perhaps that reality is like this.

    Filter bubbles describe a situation where news that we dislike or disagree
    with is automatically filtered out and this might have the effect of
    narrowing what we know. This distinction is important because echo chambers
    could be a result of filtering or they could be the result of other
    processes, but filter bubbles have to be the result of algorithmic
    filtering.' \cite{richard}
\end{quote}

In essence, all filter bubbles are echo chambers, but not necessarily
vice-versa. This implication that filter bubbles are echo chambers would suggest
that they would lead to a narrowing of the mind.

Note that Dr. Fletcher finds that these types of filter bubbles tended to result
in a person viewing more media from a varying amount of sources than they would
have otherwise \cite{richard}.

\subsection{Terminology}
The decision to use the term `bubble' when describing filters implies a
similarity to other types of bubbles. Bubbles are fragile and can be popped
easily. Some examples are the housing \cite{publications2006us} and tulip
bubbles \cite{dash2011tulipomania}. Eli Pariser thus implies that the usage of
these types of automated filters is fragile and subject to public opinion.

It must be considered what would happen if this bubble were to `pop'. In the two
above examples, the popping of the bubble led to great economic issues and
volatility. For the filter bubble to pop would likely lead to an enormous
change in paradigm for how the internet organizes content.

It may be unfair to label this model as a bubble, as unlike the housing and
tulip bubbles, the filter bubble is not a result of speculation. While
investments are certainly made into the algorithms that go behind these filters,
these algorithms at their core solve current and present problems.

For this `bubble' to pop, the underlying content and media would
similarly need to pop. The algorithms and filters used in modern-day simply
prioritize and serve the content; even a simple `most recently created'
algorithm would be considered a filter.

\subsection{Prevalence in other Media}
Though Pariser claims that filter bubbles are recent, in reality, these types of
filters have always existed. Regardless of what medium, the source of
information has always been filtered. Someone had to write the article, someone
had to decide what to put on the front page, and someone had to decide what to
put on the evening news. The difference with the internet is that the filter is
now automated, and can be based on a person's behavior and
preferences (hence the bubble).

In my experience, I have found that filter bubbles rely on proper development,
balance, and scope. I have seen countless times people on YouTube attribute
their success/failures to `the algorithm'. Similarly, these types of
algorithms apply to other social platforms and have faced their fair share of
controversy. The most recent example is the 2020 US Presidential Election, where
Facebook and Twitter were accused of censoring content \cite{time2021facebook}.

\subsection{TikTok}
Similarly to Facebook's debacle, TikTok has faced numerous controversies
regarding its algorithms. TikTok has had countless trends that have largely
affected our society as a whole. From its teeth filing trend \cite{wapostteeth}
to the `Kia/Hyundai challenge' where people would steal cars \cite{cnbccars},
these trends have had a large impact on society.

I experienced the effects of TikTok's algorithm when my mother's car
was stolen. Many insurance companies began refusing to insure Kia and Hyundai
cars, leading to a large spike in insurance rates for these cars.

Not only did TikTok not filter these types of videos, it actively delivered them
to users.

\section{Conclusion}
It is clear to see that filter bubbles are an important factor for society. The
biggest bubble when it comes to these filters is how well they are designed and
developed. Though Richard Fletcher said `Focusing on filter bubbles can cause us
to misunderstand the mechanisms at play and might also be distracting us.', he
goes on to admit that `we need to critically examine the effects of algorithmic
selection on news use'.

In short, Fletcher agrees that we should be aware and critical of these types of
filters and algorithms.

\vfill

\singlespacing
\bibliographystyle{unsrt} % Or choose a different style if needed
\bibliography{bib} % Replace 'references' with the name of your BibTeX file

\end{document}
